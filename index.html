<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- 描述信息，显示在搜索引擎结果中，可以根据实际内容更改 -->
  <meta name="description"
        content="Machine Learning Modeling for Multi-order Human Visual Motion Perception">
  <!-- 关键词，用于搜索引擎优化，可根据实际内容调整 -->
  <meta name="keywords" content="Visual motion perception, Optical flow, Second-order motion, Graph neural network, Motion segmentation">
  <!-- 视口设置，让页面在移动设备上更好显示 -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- 网页标题，将显示在浏览器标签页上，可自定义 -->
  <title>MotionModel</title>

  <!-- Google Analytics 跟踪代码，用于网站流量统计 -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!-- 加载Google字体，可根据需要修改 -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <!-- 加载CSS样式文件 -->
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- 页面图标 -->
  <link rel="icon" href="./static/images/eye.svg">

  <!-- 加载jQuery和其他JS库 -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- 导航栏 -->
<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <!-- 菜单按钮 -->
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- 首页图标，可修改链接 -->
      <a class="navbar-item" href="xxxx">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>

      <!-- 更多研究的下拉菜单 -->
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">More Research  </a>
        <div class="navbar-dropdown">
         
          <a class="navbar-item" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/4c9477b9e2c7ec0ad3f4f15077aaf85a-Paper-Conference.pdf">Motion Model</a>
          <a class="navbar-item" href="https://www.cell.com/iscience/pdf/S2589-0042(23)02384-2.pdf">Human perceived flow</a>
        </div>
      </div>
    </div>
  </div>
</nav>
  
<!-- 标题和作者信息部分 -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <!-- 主要标题，页面显示的标题，可自定义 -->
          <h1 class="title is-1 publication-title colorful-title">Machine Learning Modeling for Multi-order Human Visual Motion Perception</h1>
          <div class="is-size-5 publication-authors">
            <!-- 作者名和链接，可修改成实际作者信息 -->
            <span class="author-block">
              Zitang Sun </a><sup>1</sup>,
              Yen-Ju Chen </a><sup>1</sup>,
              Yung-hao Yang </a><sup>1</sup>,
              Yuan Li </a><sup>1</sup>,
              <a href="https://scholar.google.com/citations?user=bxhQU8EAAAAJ&hl=en"> Shin'ya Nishida* </a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <!-- 作者所属机构信息 -->
            <span class="author-block"><sup>1</sup>Cognitive Informatics Lab, Kyoto University, Japan,</span>
          
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- 论文链接，点击时弹出提示 -->
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- 视频链接，点击时弹出提示 -->
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-youtube"></i></span>
                  <span>Video</span>
                </a>
              </span>
              <!-- 代码链接，点击时弹出提示 -->
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
              <!-- 数据集链接，点击时弹出提示 -->
              <span class="link-block">
                <a href="javascript:void(0);" onclick="showAlert()" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span>
                  <span>Data</span>
                </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  /* 标题居中对齐 */
  .colorful-title {
    text-align: center;
    font-size: 2.5em; /* 根据需要调整字体大小 */
  }

  /* 为不同颜色定义类 */
  .word-color-1 { color: #ff5733; }
  .word-color-2 { color: #33c1ff; }
  .word-color-3 { color: #9b33ff; }
  .word-color-4 { color: #33ff57; }
  .word-color-5 { color: #ffd433; }
  .word-color-6 { color: #ff33a6; }
</style>

<script>
  // JavaScript代码：将标题的每个单词分配随机颜色
  document.addEventListener("DOMContentLoaded", function() {
    const title = document.querySelector(".colorful-title");
    const words = title.innerText.split(" ");
    title.innerHTML = words.map((word, index) => {
      const colorClass = `word-color-${(index % 6) + 1}`; // 分配颜色类
      return `<span class="${colorClass}">${word}</span>`;
    }).join(" ");
  });
</script>


<!-- JavaScript，用于显示提示信息 -->
<script>
  function showAlert() {
    alert("Not available currently. All data/code/benchmark will be open once the paper gets accepted.");
  }
</script>

<style>
  .scaled-video {
    width: 70vw; /* 占据视口宽度的 70% */
    height: 70vh; /* 占据视口高度的 70% */
    object-fit: contain; /* 保持视频内容完整，可能会有空白边 */
    display: block; /* 使视频为块级元素，以便居中 */
    margin: 0 auto; /* 水平居中对齐 */
  }
 .overlay-text {
    text-align: center;
    color: white;
    background: rgba(0, 0, 0, 0.5);
    padding: 10px;
    border-radius: 5px;
    max-width: 70%;
    margin-top: -20px; /* 仅调整顶部间距 */
    margin-left: auto;
    margin-right: auto; /* 水平居中 */
}
</style>


<style>
  /* 视频样式 */
  .video-element {
    width: 90vw; /* 占据视口宽度的90% */
    height: auto; /* 保持视频宽高比 */
    margin: 0 auto; /* 水平居中 */
    display: block;
  }

  /* 调整视频说明的样式 */
  figcaption {
    font-size: 1.3em;
    margin-top: 10px;
    color: #555;
    text-align: center;
  }
</style>

<style>
  /* 视频样式 */
  .video-rec {
    width: 60vw; /* 占据视口宽度的90% */
    height: auto; /* 保持视频宽高比 */
    margin: 0 auto; /* 水平居中 */
    display: block;
  }

  /* 调整视频说明的样式 */
  figcaption {
    font-size: 1.3em;
    margin-top: 10px;
    color: #555;
    text-align: center;
  }
</style>


<style>
  /* 视频样式 */
  .video-left {
    width: 90vw; /* 占据视口宽度的90% */
    height: auto; /* 保持视频宽高比 */
    margin: 0 auto; /* 水平居中 */
    display: block;
  }

  /* 调整视频说明的样式 */
  figcaption {
    font-size: 1.3em; /* 调整字体大小 */
    margin-bottom: 10px; /* 与视频间距 */
    color: #555; /* 文本颜色 */
    text-align: left; /* 左对齐文字 */
  }

  /* 视频容器样式 */
  .video-container {
    display: flex;
    flex-direction: column; /* 垂直排列 */
    align-items: center; /* 水平居中 */
    text-align: center; /* 容器内文字居中 */
  }

  /* 确保文字宽度与视频一致 */
  .video-container figcaption {
    width: 90vw; /* 与视频宽度一致 */
    margin: 0 auto 10px auto; /* 保持水平居中 */
  }
</style>


<style>
  /* 图像样式 */
  .image-element {
    width: 90vw; /* 占据视口宽度的90% */
    height: auto; /* 保持图像宽高比 */
    margin: 0 auto; /* 水平居中 */
    display: block;
  }

  /* 调整图像说明的样式 */
  .caption-text {
    max-width: 90vw; /* 限制文字宽度与图像一致 */
    font-size: 1.3em; /* 调整字体大小 */
    margin-bottom: 10px; /* 与图像的间距 */
    color: #555; /* 文字颜色 */
    text-align: left; /* 左对齐文字 */
    word-wrap: break-word; /* 防止文字超出范围 */
    overflow-wrap: break-word; /* 增强兼容性 */
  }

  /* 图像容器样式 */
  .image-container {
    display: flex;
    flex-direction: column; /* 垂直排列 */
    align-items: center; /* 水平居中 */
    text-align: center; /* 容器内文字居中 */
  }
</style>

<style>
  /* 视频样式 */
  .video-element {
    width: 90vw; /* 占据视口宽度的90% */
    height: auto; /* 保持视频宽高比 */
    margin: 0 auto; /* 水平居中 */
    display: block;
  }

  /* 调整视频说明的样式 */
  figcaption {
    font-size: 1.3em; /* 调整字体大小 */
    margin-bottom: 10px; /* 与视频间距 */
    color: #555; /* 文本颜色 */
    text-align: left; /* 左对齐文字 */
  }

  /* 视频容器样式 */
  .video-container {
    display: flex;
    flex-direction: column; /* 垂直排列 */
    align-items: center; /* 水平居中 */
    text-align: center; /* 容器内文字居中 */
  }

  /* 确保文字宽度与视频一致 */
  .video-container figcaption {
    width: 90vw; /* 与视频宽度一致 */
    margin: 0 auto 10px auto; /* 保持水平居中 */
  }
</style>

<h2 class="title is-3">Introduction</h2>
  
  <section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-element" autoplay loop muted playsinline>
        <source src="./data_for_website/1_intro.mp4" type="video/mp4">
        Your browser does not support video tags.
      </video>
      
    </figure>
  </div>
</section>

<hr class="section-divider">
  
<section class="section">
  <div class="container">
    <!-- 使用 Columns 布局 -->
    <div class="columns is-vcentered">
      <!-- 左侧视频部分 -->
      <div class="column is-half">
        <figure>
          <video class="video-element" autoplay loop muted playsinline>
            <source src="./data_for_website/2_gap_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </figure>
      </div>
      <!-- 右侧文字部分 -->
      <div class="column is-half content">
        <p>Motion estimation is an essential function for living things to interact with the world and has a wide range of application areas, 
          such as dynamic interaction between robots and the environment and autonomous driving assistance.
        </p>
      </div>
    </div>
  </div>
</section>



  <section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-element" autoplay loop muted playsinline>
        <source src="./data_for_website/2_gap_2.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      
    </figure>
  </div>
</section>





<hr class="section-divider">
<hr class="section-divider">
  <!-- 摘要部分 -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- 论文摘要内容，可以自行替换 -->
          <p>
           The objective of this study is to develop machines that naturally learn to perceive visual motion as humans do. 
            While recent advances in computer vision (CV) have enabled DNN-based models to accurately estimate optical flow in naturalistic images, 
            a significant disparity remains between CV models and the biological visual system in both architecture and behavior. 
            This disparity includes humans' ability to perceive the motion of higher-order image features (second-order motion), 
            which many CV models fail to capture due to their reliance on the intensity conservation law. 
            Our model architecture mimics the cortical V1-MT motion processing pathway, utilizing a trainable motion energy sensor bank and a recurrent self-attention network. 
            Supervised learning on diverse naturalistic movies allows the model to replicate psychophysical and physiological findings about first-order (luminance-based) motion perception. 
            For second-order motion, inspired by neuroscientific findings, the model includes an additional sensing pathway with nonlinear preprocessing before motion energy sensing, 
            implemented using a simple multi-layer 3D CNN block. 
            To explore how the brain naturally acquires second-order motion perception in natural environments---where pure second-order signals are rare---we hypothesized 
            that second-order mechanisms are critical for estimating robust object motion amidst optical fluctuations, such as highlights on glossy surfaces. 
            We trained our dual-pathway model on novel motion datasets with varying material properties of moving objects and found that 
            training to estimate motion for non-Lambertian materials naturally endowed the model with the ability to perceive second-order motion, 
            akin to humans. The resulting model effectively aligns with biological systems while generalizing to both first- and second-order motion phenomena in natural scenes.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>




  <section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-element" autoplay loop muted playsinline>
        <source src="./data_for_website/3_model_2.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      
    </figure>
  </div>
</section>

<hr class="section-divider">

<section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-element" autoplay loop muted playsinline>
        <source src="./data_for_website/4_dataset_1.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      
    </figure>
  </div>
</section>

  <section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-element" autoplay loop muted playsinline>
        <source src="./data_for_website/4_dataset_2.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      
    </figure>
  </div>
</section>


  <section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-element" autoplay loop muted playsinline>
        <source src="./data_for_website/4_dataset_3.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      
    </figure>
  </div>
</section>



  


  
  
<hr class="section-divider">
<!-- 轮播视频展示 -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <!-- 描述文字 -->
      <p class="has-text-centered is-size-5 mb-4">Swipe to browse more examples</p>

      <div id="results-carousel" class="carousel results-carousel">
        <!-- 每个视频项目 -->
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/1_KITTI_Session5_Mov1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/2_VirtualKITTI2_Session4_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/3_MPI_Sintel_NV_Session4_Mov1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/4_VIPER_Session7_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/5_Spring_Session12_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/6_Monkaa_Session4_Mov1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/7_MHOF_Session7_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/8_Driving_Session12_Mov2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/9_Flyingthings3D_Session9_Mov1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video autoplay controls muted loop playsinline height="100%">
            <source src="./static/10_TartanAir_Session2_Mov2.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  /* 样式用于让描述文字居中并适应页面风格 */
  .has-text-centered {
    text-align: center;
  }
  .is-size-5 {
    font-size: 1.3em;
  }
  .mb-4 {
    margin-bottom: 1.5rem;
  }
</style>



  <section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-element" autoplay loop muted playsinline>
        <source src="./data_for_website/4_dataset_4.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      
    </figure>
  </div>
</section>


  <hr class="section-divider">
  <section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-element" autoplay loop muted playsinline>
        <source src="./data_for_website/4_dataset_1.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      
    </figure>
  </div>
</section>

  

  <hr class="section-divider">
  <section class="section">
  <div class="container has-text-centered">
    <figure>
      <figcaption>Second-order motion is an essential function for living things to interact with the world and has a wide range of application areas, 
        such as dynamic interaction between robots and the environment and autonomous driving assistance.
      </figcaption>
      <video class="video-rec" autoplay loop muted playsinline>
        <source src="./data_for_website/5_conclu.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      
    </figure>
  </div>
</section>


<hr class="section-divider">



  <hr class="section-divider">
<!-- Teaser 主视频展示 -->
<section class="hero teaser">
  <video id="teaser" autoplay muted loop playsinline class="scaled-video">
    <source src="./data_for_website/6_firsec.mp4" type="video/mp4">
     Your browser does not support the video tag.
  </video>

  
  <h2 class="subtitle has-text-centered overlay-text">
    Several representative computer vision models and human-inspired models for motion estimation were tested on our human benchmark. 
    Here, we select the <a href="https://playing-for-benchmarks.org/download/">VIPER Benchmark</a>  and  <a href="http://sintel.is.tue.mpg.de/">MPI-Sintel Benchmark</a> as demonstrations.
    The red, yellow, and blue arrows represent human perception, computer vision (CV) models, and ground truth (GT), respectively. We introduce the Relative Consistency Index (RCI) to illustrate each model's ability to align with human perception (i.e., human bias that differs from GT). The yellow circle denotes this alignment; a larger circle indicates that the CV model's response is closer to human perception than to GT. Overall, we found that basic human-aligned computations, such as models based on motion energy calculations, capture human illusions of motion more effectively than state-of-the-art CV models.
  </h2>
</section>



  



<!-- 参考文献 BibTeX 格式 -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{xxx,
  author    = {xxxx},
  title     = {HuPerFlow: a Human Perceived Flow dataset},
  journal   = {xxx},
  year      = {2025},
}</code></pre>
  </div>
</section>

<!-- 页脚部分 -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- 链接到PDF文件 -->
      <a class="icon-link" href="./static/paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <!-- GitHub图标及链接 -->
      <a class="icon-link" href="xxx" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <!-- 网站许可证信息 -->
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
         
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
